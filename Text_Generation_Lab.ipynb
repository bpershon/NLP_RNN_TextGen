{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Lab.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "MseOuCI-eneS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text Generation"
      ]
    },
    {
      "metadata": {
        "id": "-stVShAC6Lhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Google Colaboratory notebook is paired with the tutorial on text generation. \n",
        "\n",
        "In this lab, you will\n",
        "\n",
        "\n",
        "*    create training data from a raw text corpus\n",
        "*    build and train an LSTM network using Keras\n",
        "*    implement a greedy sampler\n",
        "*    experiment with other model architectures\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xUYFe3E1CvhC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ]
    },
    {
      "metadata": {
        "id": "2Zw9j0esb-WY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad5591ee-49cf-4330-935b-018c6640b75e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524356442158,
          "user_tz": 240,
          "elapsed": 392,
          "user": {
            "displayName": "Mohit Deshpande",
            "photoUrl": "//lh6.googleusercontent.com/-fNFldn77VPk/AAAAAAAAAAI/AAAAAAAAUdQ/JQtY9irmZl4/s50-c-k-no/photo.jpg",
            "userId": "104832471965158864709"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Run setup code for this notebook to download the corpus\n",
        "\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.callbacks import Callback\n",
        "from random import randint\n",
        "\n",
        "\"\"\"Other training sets\n",
        "Shakespeare's sonnets:\n",
        "https://gist.githubusercontent.com/mohitd/387c2b98e15a5d292c9385da56c607f6/raw/2042cb4e6489671a62cc805b34c5095369733017/sonnets.txt\n",
        "\n",
        "Linux kernel code in C:\n",
        "https://gist.githubusercontent.com/mohitd/08cf6d5832a5502a68b5be5ead14d4aa/raw/a483495db3d746c3480a9fa8fb760f7dd9bd1b41/kernel.c\n",
        "\"\"\"\n",
        "\n",
        "# download corpus\n",
        "url = 'https://gist.githubusercontent.com/mohitd/387c2b98e15a5d292c9385da56c607f6/raw/2042cb4e6489671a62cc805b34c5095369733017/sonnets.txt'\n",
        "response = urllib.request.urlopen(url)\n",
        "corpus = response.read().decode('utf-8')\n",
        "print('Downloaded corpus!')\n",
        "\n",
        "# get some statistics on the corpus\n",
        "chars = list(set(corpus))\n",
        "data_size, vocab_size = len(corpus), len(chars)\n",
        "print('{} chars in corpus'.format(data_size))\n",
        "print('{} unique chars'.format(vocab_size))\n",
        "\n",
        "# construct dictionaries to creating \"embeddings\" for the characters\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
        "print('Created embedding dictionaries!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded corpus!\n",
            "Created embedding dictionaries!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnbDwiFLL5Rk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Training Data\n",
        "\n",
        "Since we are using a character-based model, the goal for our network is to classify the next character given the previous 50 characters. So we need to create training data where the input data is 50 characters and the output is the next character.\n",
        "\n",
        "Split the corpus into overlapping blocks (simply shift over by 1 character each time) of 50 characters into `sentences`. Then extract the next character after those 50 into `next_chars`. The `sentences` variable should be a list of strings, and `next_chars` should be a list of single characters.\n",
        "\n",
        "(Hint: use string slicing! e.g., `string[x:x+10]` extracts 10 characters starting at position `x`)"
      ]
    },
    {
      "metadata": {
        "id": "2nUGf4VNL7mk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39db60b0-c88b-4c44-9c1e-d52139648480",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524356445302,
          "user_tz": 240,
          "elapsed": 762,
          "user": {
            "displayName": "Mohit Deshpande",
            "photoUrl": "//lh6.googleusercontent.com/-fNFldn77VPk/AAAAAAAAAAI/AAAAAAAAUdQ/JQtY9irmZl4/s50-c-k-no/photo.jpg",
            "userId": "104832471965158864709"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_length = 50\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\"\n",
        "assert(all(len(sentence) == sentence_length for sentence in sentences))\n",
        "print('{} sentences, each {} characters long'.format(len(sentences), sentence_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "550171 sentences, each 50 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m2228M8WMnK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have string representations of the characters, we need to convert these string/character representations into numerical representations using our character \"embeddings\". These \"embeddings\" are really just one-hot vectors for each character.\n",
        "\n",
        "Iterate through each of the sentences to populate the `X` and `y` matrices. Remember that `X[i]` refers to a particular sentence, i.e., a sequence of character vectors. And `X[i,j]` refers to a particular character vector in a particular sentence. Use the `char_to_idx` dictionary to convert from characters to their index in the character vector."
      ]
    },
    {
      "metadata": {
        "id": "o2NIre_6MrGk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1082ea76-6ce5-424d-b13e-ccd571a8e31a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524356462986,
          "user_tz": 240,
          "elapsed": 11966,
          "user": {
            "displayName": "Mohit Deshpande",
            "photoUrl": "//lh6.googleusercontent.com/-fNFldn77VPk/AAAAAAAAAAI/AAAAAAAAUdQ/JQtY9irmZl4/s50-c-k-no/photo.jpg",
            "userId": "104832471965158864709"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_sentences = len(sentences)\n",
        "X = np.zeros((num_sentences, sentence_length, vocab_size), dtype=np.bool)\n",
        "y = np.zeros((num_sentences, vocab_size), dtype=np.bool)\n",
        "\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\"\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print('Created vectorized input and output')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(550171, 50, 99)\n",
            "(550171, 99)\n",
            "Created vectorized input and output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2_LWTM7JtK54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building the Model\n",
        "\n",
        "Now that we have our training data, we need to create our RNN model. For this tutorial, we will be using [Keras](https://keras.io/), an API for working with neural networks in Python.\n",
        "\n",
        "Our base model will be a sequential model, which is a linear sequence of layers. Our model will have two layers, the first of which will be our RNN. For this model, rather than the simple RNN, we will use a Long Short-Term Memory Unit or LSTM. Read the tutorial for more information on LSTMs. In Keras, the output of this layer will simply be the output at the final time step, which is customary for sequence classification. The next layer will be a fully-connected layer that performs the classification over the characters: this is the classification layer that will produce a probability distribution over all of the unique characters. \n",
        "\n",
        "Steps:\n",
        "- Add a 256-unit LSTM layer (make sure to use the correct input shape!)\n",
        "- Add a dense/fully connected layer to perform classification (make sure to use the correct number of neurons and the correct activation function!)\n",
        "- Compile the model using categorical cross-entropy as the loss function and the adam optimizer with the default parameters\n",
        "\n",
        "For reference:\n",
        "\n",
        "https://keras.io/getting-started/sequential-model-guide/\n",
        "\n",
        "https://keras.io/layers/recurrent/\n",
        "\n",
        "https://keras.io/layers/core/"
      ]
    },
    {
      "metadata": {
        "id": "MHzZgIL2tGes",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpWr0KRttOo8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sampling from an RNN\n",
        "\n",
        "Once our model is built and trained – we'll get to training in a second – we need to be able to use it to generate text. That is, after all, why we came here in the first place. We will do this by sampling from the model with an initial seed.\n",
        "\n",
        "Remember that our model works by taking a \"sentence\" of the previous 50 characters and, based on that input, predicts the next character. When we start predicting, however, we don't have any characters yet. So, to get the prediction started, we take a \"seed sentence\" from our corpus and use that for our first prediction. Each character we predict will be concatenated onto the seed, and then, once we've predicted at least 50 characters, our future predictions will be based on our actual generated text rather than text from the original corpus.\n",
        "\n",
        "Steps:\n",
        "1. Randomly select a \"seed sentence\" (sequence of 50 characters) from the corpus (or you may supply your own!)\n",
        "2. Generate a one-hot character embedding from the seed sentence\n",
        "3. Have the model predict the next character based on the preceding 50 characters. Note that the prediction will not be a single character – it will be an array of probabilities for each possible next character. Choose the one with the highest probability, i.e., the argmax!\n",
        "4. Add the highest probability character to the end of our generated text, then add it's one-hot character embedding to the end of the running generated text\n",
        "5. Repeat steps 3 & 4 until you've built up a string of predicted characters equal to the sample length \n",
        "\n",
        "Hints\n",
        "* The seed should be of size `(1, 50, vocab_size)` where 1 represents the batch size.\n",
        "* Use `model.predict(...)` with the runnning seed as input and use `idx_to_char` to convert it back to a character\n",
        "* You'll need to encode that character as a one-hot character (the size should be `(1, 1, vocab_size)`)\n",
        "* Use `np.concatenate` in combination with numpy array slicing to attach the model's prediction to the seed while retaining the `(1, 50, vocab_size)` size.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AhmhTcL-tSjO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sample_from_model(model, sample_length=100):\n",
        "  generated_text = ''\n",
        "  \"\"\"\n",
        "  YOUR CODE HERE\n",
        "  \"\"\"\n",
        "  return generated_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxclE5NeXfI2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, create a subclass of Keras's `Callback` class called `SamplerCallback`. A `Callback` class is used to provide some sort of feedback during model training. These callbacks have hooks that we can use to run code during training, e.g., `on_epoch_{begin/end}`, `on_batch_{begin/end}`, and `on_training_{begin/end}`. In this case, we can create one that will give us sample text after each training epoch. If our model is being trained properly, at the end of each training epoch, the sampled text from the model should look more and more like real text – up until a certain point, of course! We can't train a perfect model, after all.\n",
        "\n",
        "To do this, simply define a function in your Callback class named `on_epoch_end` that takes three parameters: `self`, `epoch`, and `logs` which will be called automatically at the end of each epoch. This function should sample text from the model using our previously-defined `sample_from_model` function and then print it. To access the current model being trained, use `self.model` rather than `model`, i.e., our global model. (This aids in re-usability if our model was called something different than `model`.) Then we just need to create an instance of this class and pass it as a `Callback` argument when we train our model."
      ]
    },
    {
      "metadata": {
        "id": "RTlh3ywZXl31",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SamplerCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "      pass\n",
        "      \"\"\"\n",
        "      YOUR CODE HERE\n",
        "      \"\"\"\n",
        "\n",
        "sampler_callback = SamplerCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxSjf91gt3Lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the RNN\n",
        "\n",
        "Finally, we need to train our RNN model by fitting it to our training data, which, in case you've forgotten, consists of a sequence of \"sentences\" (`X`) and a sequence of next characters (`y`). We will train our model to learn weights such that, given the \"sentence\" input, it produces the correct next character as output. Our model will train for a certain number of epochs – each epoch is one full pass over all the training data – using the specified optimizer to adjust the weights in the model to optimize the specified loss function when applied to the training data.\n",
        "\n",
        "To fit our model to the training data, we will need to specify the following parameters:\n",
        "- Training input (a numpy array)\n",
        "- Training output (a numpy array)\n",
        "- Number of training epochs (try 30)\n",
        "- A batch_size indicating the number of training samples taken in for each update of the model weights (try 256)\n",
        "- A list of callbacks (see previous section)\n",
        "\n",
        "For reference, see: https://keras.io/models/model/"
      ]
    },
    {
      "metadata": {
        "id": "2Xc__1Iht4TC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83J8_FYhNCA4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sample from the Trained Model\n",
        "\n",
        "Now that our model is trained, we can see how well it did. Sample 1000 characters from the model using the `sample_from_model` function and print it. How does it look? Does it look like Shakespeare? Does it look like English? Is it pronouncable?\n",
        "\n",
        "Hopefully the answer to all these questions is yes. Even this simple character-based model should be able to produce mostly actual English words, and Shakespearean sounding ones at that. The grammar might be a little questionable, but it shouldn't be terrible either. Given that this is a character-based model with no inherent knowledge of the concept of \"words,\" that's pretty amazing!"
      ]
    },
    {
      "metadata": {
        "id": "206Dn_OgNDsA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YOUR CODE HERE\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSuqJ-mw1Em8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you've gotten this far, you can:\n",
        "\n",
        "1. Try training your model with a different input dataset. We know that LSTMs can write Shakespeare, but what about C code? Use the other dataset and re-run all of the sections to see how well character-level models fair against code. **What if, instead of a character-level model, we tried to use a word-level model for C code? What do you expect the quality of this to be compared to a character-level model on C code?**\n",
        "\n",
        "2. Play around with the model parameters to see how they affect your output. What happens if you increase/decrease the number of hidden units in your LSTM? Or use a different optimizer? In the beginning, we organized our training data so that our model could predict the next character based on the previous 50 characters. What if it was 100 characters? What if it was 10? Do you think the sampled output would get better or worse? What are the tradeoffs to using a larger sequence?\n",
        "\n",
        "3. Recent literature seems to favor GRUs and 1D convolutional networks over LSTM because they produce similar quality results but are more efficient to train. Try these models. Do they perform better than the LSTM?\n"
      ]
    },
    {
      "metadata": {
        "id": "J_nkqboJVIFn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SANDBOX\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}